{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Deterministic Policy Gradients (DDPG)\n",
    "---\n",
    "In this notebook, we train DDPG with OpenAI Gym's BipedalWalker-v2 environment.\n",
    "\n",
    "### 1. Import the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "# imports for rendering outputs in Jupyter.\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Instantiate the Environment and Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v0')\n",
    "env.seed(10)\n",
    "agent = Agent(state_size=env.observation_space.shape[0], action_size=env.action_space.shape[0], random_seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action space: Box(1,) ... state space: Box(3,)\n"
     ]
    }
   ],
   "source": [
    "print (\"action space: {} ... state space: {}\".format(env.action_space,env.observation_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.], dtype=float32), array([-2.], dtype=float32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.high, env.action_space.low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 ... state: [0.83465323 0.55077581 0.43384926] ... action: [0.19525401] ... reward: -0.36 ... done: False\n",
      "step: 1 ... state: [0.80973004 0.58680258 0.87621922] ... action: [0.86075747] ... reward: -0.47 ... done: False\n",
      "step: 2 ... state: [0.76524393 0.64374042 1.44543478] ... action: [0.4110535] ... reward: -0.70 ... done: False\n",
      "step: 3 ... state: [0.69751612 0.71656909 1.98989812] ... action: [0.17953274] ... reward: -1.03 ... done: False\n",
      "step: 4 ... state: [0.60056898 0.79957295 2.55425485] ... action: [-0.3053808] ... reward: -1.51 ... done: False\n",
      "step: 5 ... state: [0.46957218 0.88289408 3.10812744] ... action: [0.58357644] ... reward: -2.14 ... done: False\n",
      "step: 6 ... state: [0.29161466 0.95653588 3.85783447] ... action: [-0.24965115] ... reward: -3.11 ... done: False\n",
      "step: 7 ... state: [0.0689702  0.99761872 4.53778871] ... action: [1.5670921] ... reward: -4.32 ... done: False\n",
      "step: 8 ... state: [-0.2055526   0.97864607  5.52106656] ... action: [1.8546511] ... reward: -6.21 ... done: False\n",
      "step: 9 ... state: [-0.50871431  0.86093539  6.53324877] ... action: [-0.46623394] ... reward: -8.70 ... done: False\n",
      "step: 10 ... state: [-0.77653113  0.63007889  7.10901522] ... action: [1.1669002] ... reward: -11.11 ... done: False\n",
      "step: 11 ... state: [-0.9571433   0.28961476  7.75660941] ... action: [0.11557968] ... reward: -14.13 ... done: False\n",
      "step: 12 ... state: [-0.99441541 -0.10553665  7.99115743] ... action: [0.27217823] ... reward: -15.60 ... done: False\n",
      "step: 13 ... state: [-0.87595944 -0.48238476  7.95283168] ... action: [1.7023865] ... reward: -13.29 ... done: False\n",
      "step: 14 ... state: [-0.62497627 -0.78064374  7.84640109] ... action: [-1.7158557] ... reward: -11.20 ... done: False\n",
      "step: 15 ... state: [-0.3192369  -0.94767495  7.00353992] ... action: [-1.6514828] ... reward: -8.50 ... done: False\n",
      "step: 16 ... state: [-0.02266914 -0.99974302  6.04506129] ... action: [-1.9191264] ... reward: -6.20 ... done: False\n",
      "step: 17 ... state: [ 0.22573571 -0.97418858  5.00738506] ... action: [1.3304794] ... reward: -4.31 ... done: False\n",
      "step: 18 ... state: [ 0.43632827 -0.89978755  4.47631554] ... action: [1.112627] ... reward: -3.26 ... done: False\n",
      "step: 19 ... state: [ 0.60513259 -0.79612471  3.96836893] ... action: [1.4800485] ... reward: -2.42 ... done: False\n",
      "step: 20 ... state: [ 0.73765902 -0.67517344  3.59328267] ... action: [1.9144734] ... reward: -1.84 ... done: False\n",
      "step: 21 ... state: [ 0.84055137 -0.54173185  3.37407361] ... action: [1.1966343] ... reward: -1.47 ... done: False\n",
      "step: 22 ... state: [ 0.91506284 -0.40331129  3.14726987] ... action: [-0.15408255] ... reward: -1.16 ... done: False\n",
      "step: 23 ... state: [ 0.96268302 -0.27063147  2.82167401] ... action: [1.1221167] ... reward: -0.87 ... done: False\n",
      "step: 24 ... state: [ 0.99094193 -0.13429108  2.78701791] ... action: [-1.5269023] ... reward: -0.80 ... done: False\n",
      "step: 25 ... state: [ 0.99992997 -0.01183454  2.45726425] ... action: [0.5596841] ... reward: -0.60 ... done: False\n",
      "step: 26 ... state: [0.99341975 0.11453036 2.53234096] ... action: [-1.4265869] ... reward: -0.66 ... done: False\n",
      "step: 27 ... state: [0.97251556 0.2328379  2.4042507 ] ... action: [1.7786757] ... reward: -0.64 ... done: False\n",
      "step: 28 ... state: [0.92967055 0.36839201 2.84568048] ... action: [0.08739328] ... reward: -0.95 ... done: False\n",
      "step: 29 ... state: [0.86076126 0.50900889 3.13508348] ... action: [-0.34135225] ... reward: -1.27 ... done: False\n",
      "step: 30 ... state: [0.76010942 0.64979509 3.46563731] ... action: [-0.9417775] ... reward: -1.70 ... done: False\n",
      "step: 31 ... state: [0.62325305 0.78202023 3.811717  ] ... action: [1.0969348] ... reward: -2.26 ... done: False\n",
      "step: 32 ... state: [0.43023856 0.90271523 4.56277239] ... action: [-0.17539868] ... reward: -3.35 ... done: False\n",
      "step: 33 ... state: [0.18304419 0.98310469 5.21349901] ... action: [0.2737358] ... reward: -4.64 ... done: False\n",
      "step: 34 ... state: [-0.11525561  0.99333587  5.9918879 ] ... action: [-1.9248408] ... reward: -6.44 ... done: False\n",
      "step: 35 ... state: [-0.42405712  0.90563545  6.44816368] ... action: [0.47054198] ... reward: -8.19 ... done: False\n",
      "step: 36 ... state: [-0.71583493  0.69826955  7.19797156] ... action: [0.44838288] ... reward: -10.79 ... done: False\n",
      "step: 37 ... state: [-0.92734925  0.37419697  7.78893115] ... action: [0.46773598] ... reward: -13.67 ... done: False\n",
      "step: 38 ... state: [-0.99972491 -0.02345413  8.        ] ... action: [1.7749923] ... reward: -16.13 ... done: False\n",
      "step: 39 ... state: [-0.90649497 -0.42221661  8.        ] ... action: [0.7272812] ... reward: -13.72 ... done: False\n",
      "step: 40 ... state: [-0.67818176 -0.73489421  7.79242972] ... action: [-0.5619684] ... reward: -11.44 ... done: False\n",
      "step: 41 ... state: [-0.37781705 -0.92588027  7.15696381] ... action: [-0.25187218] ... reward: -8.96 ... done: False\n",
      "step: 42 ... state: [-0.06615048 -0.99780966  6.42477278] ... action: [0.7905248] ... reward: -6.81 ... done: False\n",
      "step: 43 ... state: [ 0.22169355 -0.97511639  5.79499425] ... action: [-1.7590982] ... reward: -5.18 ... done: False\n",
      "step: 44 ... state: [ 0.44711779 -0.89447509  4.79979223] ... action: [0.6670669] ... reward: -3.53 ... done: False\n",
      "step: 45 ... state: [ 0.62488974 -0.78071301  4.22899595] ... action: [0.6825515] ... reward: -2.59 ... done: False\n",
      "step: 46 ... state: [ 0.75932977 -0.650706    3.74584392] ... action: [-1.1584698] ... reward: -1.91 ... done: False\n",
      "step: 47 ... state: [ 0.85026297 -0.52635813  3.08404395] ... action: [-1.4842948] ... reward: -1.26 ... done: False\n",
      "step: 48 ... state: [ 0.90855675 -0.41776146  2.46663113] ... action: [-0.7382866] ... reward: -0.79 ... done: False\n",
      "step: 49 ... state: [ 0.94641381 -0.3229565   2.04256705] ... action: [-0.5451569] ... reward: -0.53 ... done: False\n",
      "step: 50 ... state: [ 0.97063904 -0.24054075  1.71857614] ... action: [0.28078708] ... reward: -0.35 ... done: False\n",
      "step: 51 ... state: [ 0.98659705 -0.16317554  1.58028864] ... action: [-0.24559395] ... reward: -0.28 ... done: False\n",
      "step: 52 ... state: [ 0.99569206 -0.09272172  1.42106789] ... action: [1.9534954] ... reward: -0.21 ... done: False\n",
      "step: 53 ... state: [ 0.99994353 -0.01062735  1.64455091] ... action: [-1.5918207] ... reward: -0.27 ... done: False\n",
      "step: 54 ... state: [0.99824447 0.05922814 1.39780729] ... action: [-1.164493] ... reward: -0.20 ... done: False\n",
      "step: 55 ... state: [0.99248907 0.12233334 1.26755445] ... action: [-1.354762] ... reward: -0.18 ... done: False\n",
      "step: 56 ... state: [0.98376392 0.17946741 1.15609016] ... action: [0.6124333] ... reward: -0.17 ... done: False\n",
      "step: 57 ... state: [0.96901802 0.24699005 1.38255572] ... action: [-0.9868336] ... reward: -0.25 ... done: False\n",
      "step: 58 ... state: [0.94905864 0.3150995  1.41977322] ... action: [-0.13475691] ... reward: -0.30 ... done: False\n",
      "step: 59 ... state: [0.92014108 0.39158701 1.63588431] ... action: [-1.0222976] ... reward: -0.43 ... done: False\n",
      "step: 60 ... state: [0.88178294 0.47165543 1.77622993] ... action: [-1.3641217] ... reward: -0.56 ... done: False\n",
      "step: 61 ... state: [0.83236508 0.55422773 1.92535326] ... action: [-1.5584995] ... reward: -0.72 ... done: False\n",
      "step: 62 ... state: [0.7694624  0.63869212 2.10724913] ... action: [0.62531835] ... reward: -0.92 ... done: False\n",
      "step: 63 ... state: [0.67723322 0.73576842 2.68006597] ... action: [-1.4472682] ... reward: -1.40 ... done: False\n",
      "step: 64 ... state: [0.55906328 0.82912499 3.01480205] ... action: [-1.2136706] ... reward: -1.87 ... done: False\n",
      "step: 65 ... state: [0.40824053 0.9128744  3.4545952 ] ... action: [-0.52509934] ... reward: -2.52 ... done: False\n",
      "step: 66 ... state: [0.2157907  0.97643964 4.0604861 ] ... action: [1.283973] ... reward: -3.48 ... done: False\n",
      "step: 67 ... state: [-0.03176371  0.99949541  4.98541178] ... action: [-1.6115949] ... reward: -5.06 ... done: False\n",
      "step: 68 ... state: [-0.30166046  0.95341542  5.4932941 ] ... action: [1.3517796] ... reward: -6.54 ... done: False\n",
      "step: 69 ... state: [-0.58670984  0.80979723  6.4111226 ] ... action: [-1.6156064] ... reward: -8.94 ... done: False\n",
      "step: 70 ... state: [-0.82250212  0.56876204  6.77612956] ... action: [1.9058379] ... reward: -11.03 ... done: False\n",
      "step: 71 ... state: [-0.97353603  0.22853357  7.48857678] ... action: [-0.1253952] ... reward: -14.08 ... done: False\n",
      "step: 72 ... state: [-0.98854773 -0.15090853  7.64116767] ... action: [1.9070444] ... reward: -14.78 ... done: False\n",
      "step: 73 ... state: [-0.85658097 -0.51601264  7.81404293] ... action: [0.41938207] ... reward: -12.86 ... done: False\n",
      "step: 74 ... state: [-0.60845309 -0.79358984  7.48994077] ... action: [0.9570543] ... reward: -10.56 ... done: False\n",
      "step: 75 ... state: [-0.29761603 -0.95468566  7.03830653] ... action: [-1.8432488] ... reward: -8.47 ... done: False\n",
      "step: 76 ... state: [ 9.56985017e-05 -9.99999995e-01  6.04580497e+00] ... action: [-0.86877215] ... reward: -6.12 ... done: False\n",
      "step: 77 ... state: [ 0.25550515 -0.9668077   5.16548915] ... action: [-1.5192138] ... reward: -4.39 ... done: False\n",
      "step: 78 ... state: [ 0.45199023 -0.89202289  4.21250131] ... action: [-0.8154392] ... reward: -2.99 ... done: False\n",
      "step: 79 ... state: [ 0.59723846 -0.80206373  3.42116826] ... action: [-1.5250891] ... reward: -2.04 ... done: False\n",
      "step: 80 ... state: [ 0.6958455  -0.71819151  2.59085709] ... action: [-0.7280673] ... reward: -1.31 ... done: False\n",
      "step: 81 ... state: [ 0.76222705 -0.64730975  1.94300337] ... action: [-0.34294802] ... reward: -0.87 ... done: False\n",
      "step: 82 ... state: [ 0.80581507 -0.59216727  1.40607885] ... action: [-1.74341] ... reward: -0.60 ... done: False\n",
      "step: 83 ... state: [ 0.82605563 -0.56358858  0.7004419 ] ... action: [0.76988846] ... reward: -0.41 ... done: False\n",
      "step: 84 ... state: [ 0.83697636 -0.54723905  0.39323373] ... action: [0.26640582] ... reward: -0.35 ... done: False\n",
      "step: 85 ... state: [ 0.83759872 -0.54628599  0.02276532] ... action: [-0.93844205] ... reward: -0.33 ... done: False\n",
      "step: 86 ... state: [ 0.82289466 -0.56819397 -0.52771549] ... action: [0.09299222] ... reward: -0.39 ... done: False\n",
      "step: 87 ... state: [ 0.79529332 -0.60622483 -0.93991213] ... action: [-1.624238] ... reward: -0.52 ... done: False\n",
      "step: 88 ... state: [ 0.74302598 -0.66926258 -1.63821645] ... action: [0.30378598] ... reward: -0.81 ... done: False\n",
      "step: 89 ... state: [ 0.66899117 -0.74327035 -2.09459549] ... action: [1.7171848] ... reward: -1.14 ... done: False\n",
      "step: 90 ... state: [ 0.57542781 -0.81785258 -2.39447054] ... action: [-0.72572416] ... reward: -1.49 ... done: False\n",
      "step: 91 ... state: [ 0.44151927 -0.89725177 -3.11671859] ... action: [0.6696415] ... reward: -2.21 ... done: False\n",
      "step: 92 ... state: [ 0.26945846 -0.96301201 -3.68921119] ... action: [-1.4728086] ... reward: -3.05 ... done: False\n",
      "step: 93 ... state: [ 0.04119941 -0.99915094 -4.63239149] ... action: [0.8653088] ... reward: -4.49 ... done: False\n",
      "step: 94 ... state: [-0.21958283 -0.97559386 -5.25195838] ... action: [-0.84237564] ... reward: -5.97 ... done: False\n",
      "step: 95 ... state: [-0.50284528 -0.86437644 -6.11001012] ... action: [-1.2672346] ... reward: -8.14 ... done: False\n",
      "step: 96 ... state: [-0.76709861 -0.6415292  -6.94837763] ... action: [0.34605175] ... reward: -10.81 ... done: False\n",
      "step: 97 ... state: [-0.94681434 -0.32178036 -7.37761677] ... action: [-1.9195698] ... reward: -13.37 ... done: False\n",
      "step: 98 ... state: [-0.99770685  0.06768333 -7.90688752] ... action: [1.3157601] ... reward: -15.70 ... done: False\n",
      "step: 99 ... state: [-0.90015409  0.43557159 -7.658761  ] ... action: [-1.9812181] ... reward: -13.11 ... done: False\n",
      "step: 100 ... state: [-0.67329769  0.7393715  -7.62926503] ... action: [0.71126616] ... reward: -11.15 ... done: False\n",
      "step: 101 ... state: [-0.38042665  0.9248111  -6.96804648] ... action: [-0.9199681] ... reward: -8.70 ... done: False\n",
      "step: 102 ... state: [-0.06957965  0.9975764  -6.41243337] ... action: [0.9407761] ... reward: -6.80 ... done: False\n",
      "step: 103 ... state: [ 0.2050559   0.97875026 -5.52313466] ... action: [1.8487542] ... reward: -4.92 ... done: False\n",
      "step: 104 ... state: [ 0.41878666  0.90808465 -4.51175883] ... action: [-1.0049875] ... reward: -3.33 ... done: False\n",
      "step: 105 ... state: [ 0.59009857  0.80733121 -3.98144347] ... action: [0.30462933] ... reward: -2.47 ... done: False\n",
      "step: 106 ... state: [ 0.71574721  0.69835946 -3.33025066] ... action: [0.36816773] ... reward: -1.71 ... done: False\n",
      "step: 107 ... state: [ 0.80475122  0.59361222 -2.75125591] ... action: [0.28900763] ... reward: -1.16 ... done: False\n",
      "step: 108 ... state: [ 0.86662153  0.49896605 -2.2626956 ] ... action: [-1.1076735] ... reward: -0.79 ... done: False\n",
      "step: 109 ... state: [ 0.91322175  0.40746293 -2.05462209] ... action: [1.810996] ... reward: -0.60 ... done: False\n",
      "step: 110 ... state: [ 0.94080276  0.33895452 -1.47737548] ... action: [-0.21149848] ... reward: -0.34 ... done: False\n",
      "step: 111 ... state: [ 0.96020496  0.27929632 -1.25488436] ... action: [1.3856347] ... reward: -0.24 ... done: False\n",
      "step: 112 ... state: [ 0.97105613  0.2388514  -0.83756692] ... action: [0.7979171] ... reward: -0.13 ... done: False\n",
      "step: 113 ... state: [ 0.97713702  0.21261054 -0.5387408 ] ... action: [-0.8102522] ... reward: -0.08 ... done: False\n",
      "step: 114 ... state: [ 0.98215411  0.18807791 -0.50082073] ... action: [1.2551913] ... reward: -0.06 ... done: False\n",
      "step: 115 ... state: [ 0.9837306   0.17964994 -0.17148359] ... action: [-0.41397703] ... reward: -0.04 ... done: False\n",
      "step: 116 ... state: [ 0.98460644  0.17478604 -0.09884269] ... action: [1.5244128] ... reward: -0.03 ... done: False\n",
      "step: 117 ... state: [0.98224256 0.18761542 0.26090875] ... action: [0.32509148] ... reward: -0.04 ... done: False\n",
      "step: 118 ... state: [0.97776893 0.2096853  0.45038403] ... action: [1.5269414] ... reward: -0.07 ... done: False\n",
      "step: 119 ... state: [0.96814393 0.25039434 0.83668922] ... action: [0.77012634] ... reward: -0.13 ... done: False\n",
      "step: 120 ... state: [0.9523068  0.3051422  1.14000393] ... action: [0.9010171] ... reward: -0.23 ... done: False\n",
      "step: 121 ... state: [0.92669008 0.37582642 1.50401315] ... action: [0.00529753] ... reward: -0.37 ... done: False\n",
      "step: 122 ... state: [0.8894654  0.45700252 1.78667759] ... action: [1.8243345] ... reward: -0.55 ... done: False\n",
      "step: 123 ... state: [0.82827388 0.56032346 2.40307966] ... action: [0.5759608] ... reward: -0.93 ... done: False\n",
      "step: 124 ... state: [0.73829181 0.67448143 2.90971638] ... action: [-0.3045798] ... reward: -1.39 ... done: False\n",
      "step: 125 ... state: [0.61472693 0.78874001 3.36989048] ... action: [0.42557284] ... reward: -1.96 ... done: False\n",
      "step: 126 ... state: [0.44464299 0.89570788 4.02528141] ... action: [-1.9232272] ... reward: -2.86 ... done: False\n",
      "step: 127 ... state: [0.2380394  0.9712555  4.40857825] ... action: [-0.79370075] ... reward: -3.71 ... done: False\n",
      "step: 128 ... state: [-0.01055131  0.99994433  5.01796476] ... action: [0.64069414] ... reward: -5.02 ... done: False\n",
      "step: 129 ... state: [-0.29910337  0.95422072  5.86402713] ... action: [-0.83968955] ... reward: -6.95 ... done: False\n",
      "step: 130 ... state: [-0.58626431  0.81011984  6.45373923] ... action: [0.47206172] ... reward: -8.99 ... done: False\n",
      "step: 131 ... state: [-0.83219062  0.55448965  7.13213837] ... action: [-0.2849252] ... reward: -11.61 ... done: False\n",
      "step: 132 ... state: [-0.97750961  0.21089087  7.50526683] ... action: [-1.4581038] ... reward: -14.21 ... done: False\n",
      "step: 133 ... state: [-0.98726713 -0.15907113  7.44471942] ... action: [-0.8068707] ... reward: -14.43 ... done: False\n",
      "step: 134 ... state: [-0.86783458 -0.49685324  7.20438547] ... action: [0.27985963] ... reward: -12.06 ... done: False\n",
      "step: 135 ... state: [-0.64966303 -0.7602223   6.87372449] ... action: [0.36349106] ... reward: -9.91 ... done: False\n",
      "step: 136 ... state: [-0.37948262 -0.92519886  6.35808142] ... action: [0.297301] ... reward: -7.88 ... done: False\n",
      "step: 137 ... state: [-0.10361187 -0.99461781  5.70877742] ... action: [0.6128033] ... reward: -6.06 ... done: False\n",
      "step: 138 ... state: [ 0.14838854 -0.98892914  5.05473456] ... action: [0.6084131] ... reward: -4.58 ... done: False\n",
      "step: 139 ... state: [ 0.36082614 -0.9326331   4.40429967] ... action: [-0.27432626] ... reward: -3.38 ... done: False\n",
      "step: 140 ... state: [ 0.52467845 -0.85130049  3.6636759 ] ... action: [1.5861864] ... reward: -2.38 ... done: False\n",
      "step: 141 ... state: [ 0.65599018 -0.75476942  3.2631285 ] ... action: [-0.5297525] ... reward: -1.80 ... done: False\n",
      "step: 142 ... state: [ 0.74888184 -0.66270354  2.61758855] ... action: [-0.2565403] ... reward: -1.21 ... done: False\n",
      "step: 143 ... state: [ 0.81369299 -0.58129487  2.08207985] ... action: [1.5676935] ... reward: -0.82 ... done: False\n",
      "step: 144 ... state: [ 0.86469374 -0.50229945  1.88126273] ... action: [1.2247759] ... reward: -0.63 ... done: False\n",
      "step: 145 ... state: [ 0.90396501 -0.42760644  1.68825452] ... action: [0.8155543] ... reward: -0.48 ... done: False\n",
      "step: 146 ... state: [ 0.93328266 -0.35914268  1.48988284] ... action: [-1.5990925] ... reward: -0.36 ... done: False\n",
      "step: 147 ... state: [ 0.94976379 -0.31296763  0.98066195] ... action: [1.6779305] ... reward: -0.20 ... done: False\n",
      "step: 148 ... state: [ 0.96418722 -0.26522256  0.9976258 ] ... action: [0.8569652] ... reward: -0.17 ... done: False\n",
      "step: 149 ... state: [ 0.97544317 -0.22025127  0.92725366] ... action: [1.995388] ... reward: -0.14 ... done: False\n",
      "step: 150 ... state: [ 0.98575289 -0.16820002  1.06137341] ... action: [-1.4022068] ... reward: -0.14 ... done: False\n",
      "step: 151 ... state: [ 0.99120049 -0.13236913  0.72489238] ... action: [1.4725043] ... reward: -0.07 ... done: False\n",
      "step: 152 ... state: [ 0.99591361 -0.09031099  0.84649117] ... action: [-1.3500283] ... reward: -0.08 ... done: False\n",
      "step: 153 ... state: [ 0.99810199 -0.06158253  0.57625368] ... action: [0.46223825] ... reward: -0.04 ... done: False\n",
      "step: 154 ... state: [ 0.99949914 -0.03164611  0.59940252] ... action: [-1.5047201] ... reward: -0.04 ... done: False\n",
      "step: 155 ... state: [ 0.99989984 -0.01415293  0.34995992] ... action: [1.3920329] ... reward: -0.01 ... done: False\n",
      "step: 156 ... state: [0.99991217 0.01325372 0.54815015] ... action: [1.2292758] ... reward: -0.03 ... done: False\n",
      "step: 157 ... state: [0.99873129 0.05035689 0.74248181] ... action: [0.27640295] ... reward: -0.06 ... done: False\n",
      "step: 158 ... state: [0.99582011 0.09133622 0.82170992] ... action: [-0.3712668] ... reward: -0.08 ... done: False\n",
      "step: 159 ... state: [0.99114334 0.13279636 0.83452207] ... action: [-1.723332] ... reward: -0.09 ... done: False\n",
      "step: 160 ... state: [0.98609274 0.16619602 0.67561953] ... action: [0.7897151] ... reward: -0.07 ... done: False\n",
      "step: 161 ... state: [0.9774208  0.21130211 0.91872381] ... action: [-0.18582927] ... reward: -0.13 ... done: False\n",
      "step: 162 ... state: [0.96499467 0.26226948 1.049326  ] ... action: [0.8882224] ... reward: -0.18 ... done: False\n",
      "step: 163 ... state: [0.94462829 0.32814233 1.37926147] ... action: [1.4655293] ... reward: -0.30 ... done: False\n",
      "step: 164 ... state: [0.91037942 0.41377447 1.84519762] ... action: [1.902086] ... reward: -0.53 ... done: False\n",
      "step: 165 ... state: [0.85323548 0.52152585 2.44084137] ... action: [1.4232134] ... reward: -0.90 ... done: False\n",
      "step: 166 ... state: [0.76425455 0.64491471 3.04546776] ... action: [-1.9531437] ... reward: -1.42 ... done: False\n",
      "step: 167 ... state: [0.65037313 0.7596149  3.23618223] ... action: [-0.56008774] ... reward: -1.79 ... done: False\n",
      "step: 168 ... state: [0.49859877 0.86683289 3.72188025] ... action: [0.9199622] ... reward: -2.49 ... done: False\n",
      "step: 169 ... state: [0.2921571  0.95637034 4.50999925] ... action: [-1.3134813] ... reward: -3.66 ... done: False\n",
      "step: 170 ... state: [0.04495367 0.99898907 5.03025481] ... action: [0.08414643] ... reward: -4.86 ... done: False\n",
      "step: 171 ... state: [-0.24220425  0.97022528  5.79211858] ... action: [-1.7826481] ... reward: -6.65 ... done: False\n",
      "step: 172 ... state: [-0.52885986  0.84870917  6.25239033] ... action: [-1.2000139] ... reward: -8.44 ... done: False\n",
      "step: 173 ... state: [-0.77876997  0.6273096   6.70892012] ... action: [-1.9259129] ... reward: -10.57 ... done: False\n",
      "step: 174 ... state: [-0.94488016  0.32741637  6.89051539] ... action: [1.1747909] ... reward: -12.63 ... done: False\n",
      "step: 175 ... state: [-0.99948654 -0.0320414   7.3122963 ] ... action: [-1.1043012] ... reward: -15.02 ... done: False\n",
      "step: 176 ... state: [-0.92560027 -0.3785025   7.12262007] ... action: [-0.6185933] ... reward: -12.65 ... done: False\n",
      "step: 177 ... state: [-0.74818395 -0.66349135  6.74595421] ... action: [1.7123252] ... reward: -10.39 ... done: False\n",
      "step: 178 ... state: [-0.49693351 -0.86778862  6.50518448] ... action: [0.8176576] ... reward: -8.60 ... done: False\n",
      "step: 179 ... state: [-0.21941218 -0.97563225  5.97699165] ... action: [-1.8726443] ... reward: -6.79 ... done: False\n",
      "step: 180 ... state: [ 0.02700333 -0.99963534  4.96437081] ... action: [-1.3412234] ... reward: -4.85 ... done: False\n",
      "step: 181 ... state: [ 0.22571767 -0.97419276  4.0134608 ] ... action: [0.4859136] ... reward: -3.41 ... done: False\n",
      "step: 182 ... state: [ 0.38523717 -0.9228176   3.35570327] ... action: [0.30891436] ... reward: -2.51 ... done: False\n",
      "step: 183 ... state: [ 0.50636242 -0.86232076  2.70992723] ... action: [-1.0484288] ... reward: -1.82 ... done: False\n",
      "step: 184 ... state: [ 0.58611643 -0.81022684  1.90592234] ... action: [1.736856] ... reward: -1.26 ... done: False\n",
      "step: 185 ... state: [ 0.64742154 -0.76213211  1.55878061] ... action: [0.45586383] ... reward: -0.99 ... done: False\n",
      "step: 186 ... state: [ 0.68672522 -0.7269171   1.0555611 ] ... action: [0.14253122] ... reward: -0.77 ... done: False\n",
      "step: 187 ... state: [ 0.70580725 -0.70840393  0.53175296] ... action: [0.3596399] ... reward: -0.65 ... done: False\n",
      "step: 188 ... state: [ 0.70773135 -0.70648166  0.054396  ] ... action: [0.9204881] ... reward: -0.62 ... done: False\n",
      "step: 189 ... state: [ 0.69571315 -0.71831971 -0.33739202] ... action: [-0.75222003] ... reward: -0.65 ... done: False\n",
      "step: 190 ... state: [ 0.6593576  -0.75182947 -0.98896481] ... action: [-0.40711576] ... reward: -0.82 ... done: False\n",
      "step: 191 ... state: [ 0.59660877 -0.80253223 -1.61390428] ... action: [-1.160625] ... reward: -1.13 ... done: False\n",
      "step: 192 ... state: [ 0.49668393 -0.86793149 -2.3898972 ] ... action: [-1.2552279] ... reward: -1.68 ... done: False\n",
      "step: 193 ... state: [ 0.35069901 -0.93648823 -3.22913001] ... action: [1.7774895] ... reward: -2.52 ... done: False\n",
      "step: 194 ... state: [ 0.17418079 -0.98471369 -3.66487275] ... action: [0.9582032] ... reward: -3.29 ... done: False\n",
      "step: 195 ... state: [-0.03790102 -0.9992815  -4.25967753] ... action: [-0.03816476] ... reward: -4.40 ... done: False\n",
      "step: 196 ... state: [-0.28466147 -0.95862811 -5.01486337] ... action: [-1.0903414] ... reward: -5.97 ... done: False\n",
      "step: 197 ... state: [-0.55096701 -0.83452702 -5.89738567] ... action: [-0.98257405] ... reward: -8.12 ... done: False\n",
      "step: 198 ... state: [-0.79381458 -0.60815986 -6.67066705] ... action: [-1.7678833] ... reward: -10.64 ... done: False\n",
      "step: 199 ... state: [-0.95990255 -0.28033391 -7.39196943] ... action: [-0.2623335] ... reward: -13.63 ... done: True\n"
     ]
    }
   ],
   "source": [
    "# lets play a random episode\n",
    "\n",
    "state = env.reset()\n",
    "done = False\n",
    "step = 0\n",
    "while (not done):\n",
    "    action = env.action_space.sample()\n",
    "    next_state,reward,done,_= env.step(action)\n",
    "    \n",
    "    print (\"step: {} ... state: {} ... action: {} ... reward: {:.2f} ... done: {}\".format(step,state,\n",
    "                                                                                      action,reward,done))  \n",
    "    state = next_state\n",
    "    step+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the Agent with DDPG\n",
    "\n",
    "Run the code cell below to train the agent from scratch.  Alternatively, you can skip to the next code cell to load the pre-trained weights from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parminder0407/anaconda3/envs/cv3/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100 ... Average reward: -1491.11 ... Max_reward: -1016.99\n",
      "Episode 200 ... Average reward: -746.51 ... Max_reward: -1.64\n",
      "Episode 300 ... Average reward: -285.81 ... Max_reward: -0.90\n",
      "Episode 400 ... Average reward: -334.94 ... Max_reward: -0.90\n",
      "Episode 500 ... Average reward: -284.30 ... Max_reward: -0.72\n",
      "Episode 600 ... Average reward: -238.97 ... Max_reward: -0.72\n",
      "Episode 700 ... Average reward: -178.73 ... Max_reward: -0.72\n",
      "Episode 800 ... Average reward: -342.03 ... Max_reward: -0.72\n",
      "Episode 900 ... Average reward: -237.58 ... Max_reward: -0.39\n",
      "Episode 1000 ... Average reward: -338.69 ... Max_reward: -0.39\n",
      "Episode 1100 ... Average reward: -240.65 ... Max_reward: -0.39\n",
      "Episode 1200 ... Average reward: -190.41 ... Max_reward: -0.39\n",
      "Episode 1300 ... Average reward: -285.36 ... Max_reward: -0.39\n",
      "Episode 1400 ... Average reward: -195.26 ... Max_reward: -0.32\n",
      "Episode 1500 ... Average reward: -373.68 ... Max_reward: -0.32\n",
      "Episode 1600 ... Average reward: -378.18 ... Max_reward: -0.32\n",
      "Episode 1700 ... Average reward: -401.45 ... Max_reward: -0.32\n",
      "Episode 1800 ... Average reward: -325.22 ... Max_reward: -0.06\n",
      "Episode 1900 ... Average reward: -277.99 ... Max_reward: -0.06\n",
      "Episode 2000 ... Average reward: -171.47 ... Max_reward: -0.06\n"
     ]
    }
   ],
   "source": [
    "def ddpg(n_episodes=2000, max_t=200):\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    max_score = -np.Inf\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = env.reset()\n",
    "        agent.reset()\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_deque.append(score)\n",
    "        scores.append(score)\n",
    "        if (score > max_score):\n",
    "            max_score=score\n",
    "        #print('\\rEpisode {}\\tAverage Score: {:.2f}\\tScore: {:.2f}'.format(i_episode, np.mean(scores_deque), score), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            print('\\rEpisode {} ... Average reward: {:.2f} ... Max_reward: {:.2f}'.format(i_episode, np.mean(scores_deque),max_score))   \n",
    "    return scores\n",
    "\n",
    "scores = ddpg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes=2000\n",
    "max_t=200\n",
    "scores_deque = deque(maxlen=100)\n",
    "scores = []\n",
    "max_score = -np.Inf\n",
    "for i_episode in range(1, n_episodes+1):\n",
    "    state = env.reset()\n",
    "    agent.reset()\n",
    "    score = 0\n",
    "    for t in range(max_t):\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        agent.step(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        score += reward\n",
    "        if done:\n",
    "            break \n",
    "    scores_deque.append(score)\n",
    "    scores.append(score)\n",
    "    if (score > max_score):\n",
    "        max_score=score\n",
    "    #print('\\rEpisode {}\\tAverage Score: {:.2f}\\tScore: {:.2f}'.format(i_episode, np.mean(scores_deque), score), end=\"\")\n",
    "    if i_episode % 100 == 0:\n",
    "        torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "        torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "        print('\\rEpisode {} ... Average reward: {:.2f} ... Max_reward: {:.2f}'.format(i_episode, \n",
    "                                                                        np.mean(scores_deque),max_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Watch a Smart Agent!\n",
    "\n",
    "In the next code cell, you will load the trained weights from file to watch a smart agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to animate a list of frames\n",
    "def animate_frames(frames):\n",
    "    plt.figure(dpi = 72)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # color option for plotting\n",
    "    # use Greys for greyscale\n",
    "    cmap = None if len(frames[0].shape)==3 else 'Greys'\n",
    "    patch = plt.imshow(frames[0], cmap=cmap)  \n",
    "\n",
    "    fanim = animation.FuncAnimation(plt.gcf(), \\\n",
    "        lambda x: patch.set_data(frames[x]), frames = len(frames), interval=30)\n",
    "    \n",
    "    display(display_animation(fanim, default_mode='once'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parminder0407/anaconda3/envs/cv3/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "ename": "NoSuchDisplayException",
     "evalue": "Cannot connect to \"None\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchDisplayException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e68a24c2f750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv3/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv3/lib/python3.6/site-packages/gym/envs/classic_control/pendulum.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv3/lib/python3.6/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error occured while running `from pyglet.gl import *`\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HINT: make sure you have OpenGL install. On Ubuntu, you can run 'apt-get install python-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work: 'xvfb-run -s \\\"-screen 0 1400x900x24\\\" python <your_script.py>'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv3/lib/python3.6/site-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;31m# trickery is for circular import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0m_pyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/cv3/lib/python3.6/site-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1894\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_pyglet_docgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1896\u001b[0;31m     \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_shadow_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv3/lib/python3.6/site-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m_create_shadow_window\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWindow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0m_shadow_window\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWindow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0m_shadow_window\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv3/lib/python3.6/site-packages/pyglet/window/xlib/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_handlers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXlibWindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mglobal\u001b[0m \u001b[0m_can_detect_autorepeat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv3/lib/python3.6/site-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, width, height, caption, resizable, style, fullscreen, visible, vsync, display, screen, config, context, mode)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             \u001b[0mdisplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_platform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv3/lib/python3.6/site-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36mget_default_display\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDisplay\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m         \"\"\"\n\u001b[0;32m-> 1845\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_pyglet_docgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv3/lib/python3.6/site-packages/pyglet/canvas/__init__.py\u001b[0m in \u001b[0;36mget_display\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;31m# Otherwise, create a new display and return it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_pyglet_docgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv3/lib/python3.6/site-packages/pyglet/canvas/xlib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, x_screen)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXOpenDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNoSuchDisplayException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot connect to \"%s\"'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mscreen_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXScreenCount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchDisplayException\u001b[0m: Cannot connect to \"None\""
     ]
    }
   ],
   "source": [
    "agent.actor_local.load_state_dict(torch.load('checkpoint_actor.pth'))\n",
    "agent.critic_local.load_state_dict(torch.load('checkpoint_critic.pth'))\n",
    "\n",
    "frames = []\n",
    "state = env.reset()\n",
    "agent.reset()\n",
    "for t in range(1000):\n",
    "    action = agent.act(state)\n",
    "    frames.append(env.render(mode='rgb_array')) \n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    state=next_state\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "env.close()\n",
    "animate_frames(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv3",
   "language": "python",
   "name": "cv3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
