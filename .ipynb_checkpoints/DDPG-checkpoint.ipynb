{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Deterministic Policy Gradients (DDPG)\n",
    "---\n",
    "In this notebook, we train DDPG with OpenAI Gym's BipedalWalker-v2 environment.\n",
    "\n",
    "### 1. Import the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "# imports for rendering outputs in Jupyter.\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Instantiate the Environment and Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('BipedalWalker-v2')\n",
    "env.seed(10)\n",
    "agent = Agent(state_size=env.observation_space.shape[0], action_size=env.action_space.shape[0], random_seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action space: Box(4,) ... state space: Box(24,)\n"
     ]
    }
   ],
   "source": [
    "print (\"action space: {} ... state space: {}\".format(env.action_space,env.observation_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 1., 1.], dtype=float32),\n",
       " array([-1., -1., -1., -1.], dtype=float32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.high, env.action_space.low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 ... state: [ 2.74737482e-03 -1.79915968e-05  1.39956169e-03 -1.59998775e-02] ... action: [0.09762701 0.43037874 0.20552675 0.08976637] ... reward: -0.02 ... done: False\n",
      "\n",
      "step: 1 ... state: [ 0.00245546 -0.00693401  0.00706781  0.01954999] ... action: [-0.1526904   0.29178822 -0.12482557  0.78354603] ... reward: -0.04 ... done: False\n",
      "\n",
      "step: 2 ... state: [0.0025492  0.00254582 0.00921938 0.0067264 ] ... action: [ 0.92732555 -0.23311697  0.5834501   0.05778984] ... reward: -0.18 ... done: False\n",
      "\n",
      "step: 3 ... state: [-0.02497778 -0.05565673 -0.03224418 -0.01146388] ... action: [ 0.13608912  0.85119325 -0.85792786 -0.8257414 ] ... reward: -0.15 ... done: False\n",
      "\n",
      "step: 4 ... state: [-0.03810721 -0.02684057 -0.01018923 -0.00028272] ... action: [-0.9595632   0.6652397   0.5563135   0.74002427] ... reward: -0.08 ... done: False\n",
      "\n",
      "step: 5 ... state: [-0.04034055 -0.00448921  0.02451716  0.07418973] ... action: [ 0.9572367   0.59831715 -0.07704128  0.56105834] ... reward: -0.13 ... done: False\n",
      "\n",
      "step: 6 ... state: [-0.05752897 -0.03441593  0.01659381  0.06765851] ... action: [-0.76345116  0.27984205 -0.71329343  0.88933784] ... reward: 0.01 ... done: False\n",
      "\n",
      "step: 7 ... state: [-0.04742908  0.02015501  0.05315211  0.0822543 ] ... action: [ 0.04369664 -0.17067613 -0.47088876  0.5484674 ] ... reward: 0.07 ... done: False\n",
      "\n",
      "step: 8 ... state: [-0.0325623   0.02969866  0.04517179  0.10635004] ... action: [-0.08769934  0.1368679  -0.9624204   0.23527099] ... reward: 0.08 ... done: False\n",
      "\n",
      "step: 9 ... state: [-0.0164213   0.03227819  0.05401522  0.09184275] ... action: [0.22419144 0.23386799 0.8874962  0.3636406 ] ... reward: -0.05 ... done: False\n",
      "\n",
      "step: 10 ... state: [-0.02086555 -0.00885637  0.03070331  0.07382854] ... action: [-0.2809842  -0.12593609  0.3952624  -0.8795491 ] ... reward: -0.08 ... done: False\n",
      "\n",
      "step: 11 ... state: [-0.02890876 -0.01608941  0.01602553  0.05242187] ... action: [ 0.33353344  0.34127575 -0.5792349  -0.7421474 ] ... reward: -0.06 ... done: False\n",
      "\n",
      "step: 12 ... state: [-0.03270517 -0.00761539  0.01862116  0.0361641 ] ... action: [-0.3691433  -0.27257845  0.14039354 -0.12279698] ... reward: -0.01 ... done: False\n",
      "\n",
      "step: 13 ... state: [-0.0328809  -0.0003912   0.01835848  0.01785957] ... action: [ 0.9767477  -0.79591036 -0.5822465  -0.677381  ] ... reward: -0.11 ... done: False\n",
      "\n",
      "step: 14 ... state: [-0.04027299 -0.01480291  0.01064349  0.00444693] ... action: [ 0.30621666 -0.4934168  -0.06737845 -0.5111488 ] ... reward: -0.09 ... done: False\n",
      "\n",
      "step: 15 ... state: [-0.0520908  -0.02366338  0.0055403  -0.0122085 ] ... action: [-0.68206084 -0.7792497   0.31265917 -0.7236341 ] ... reward: -0.09 ... done: False\n",
      "\n",
      "step: 16 ... state: [-0.05716193 -0.01018547  0.01270016 -0.03285013] ... action: [-0.6068353  -0.26254967  0.6419865  -0.80579746] ... reward: -0.09 ... done: False\n",
      "\n",
      "step: 17 ... state: [-0.06298675 -0.01171623  0.01111755 -0.05335963] ... action: [ 0.6758898  -0.8078032   0.95291895 -0.0626976 ] ... reward: -0.16 ... done: False\n",
      "\n",
      "step: 18 ... state: [-0.08038425 -0.03488452 -0.00221445 -0.06914218] ... action: [ 0.9535222   0.20969103  0.47852716 -0.9216244 ] ... reward: -0.20 ... done: False\n",
      "\n",
      "step: 19 ... state: [-0.10490359 -0.04913311 -0.00853194 -0.08341329] ... action: [-0.43438607 -0.7596069  -0.4077196  -0.7625446 ] ... reward: -0.10 ... done: False\n",
      "\n",
      "step: 20 ... state: [-0.113897   -0.01805255  0.0087796  -0.10238965] ... action: [-0.36403364 -0.17147401 -0.871705    0.38494423] ... reward: 0.03 ... done: False\n",
      "\n",
      "step: 21 ... state: [-0.10315292  0.02139277  0.03698362 -0.09916357] ... action: [ 0.13320291 -0.46922103  0.04649611 -0.812119  ] ... reward: 0.01 ... done: False\n",
      "\n",
      "step: 22 ... state: [-0.09629431  0.01359365  0.02757021 -0.13425879] ... action: [ 0.15189299  0.8585924  -0.36286208  0.33482075] ... reward: 0.04 ... done: False\n",
      "\n",
      "step: 23 ... state: [-0.08601809  0.02049692  0.04955736 -0.12029821] ... action: [-0.7364043   0.4326544  -0.42118782 -0.6336173 ] ... reward: 0.11 ... done: False\n",
      "\n",
      "step: 24 ... state: [-0.06142445  0.04904678  0.06220779 -0.15277295] ... action: [ 0.17302588 -0.9597849   0.65788007 -0.99060905] ... reward: -0.02 ... done: False\n",
      "\n",
      "step: 25 ... state: [-0.05441392  0.01397751  0.02673969 -0.1835519 ] ... action: [ 0.35563308 -0.45998406  0.47038805  0.9243771 ] ... reward: -0.09 ... done: False\n",
      "\n",
      "step: 26 ... state: [-0.06173464 -0.01469692  0.01668382 -0.18109945] ... action: [-0.50249374  0.15231466  0.18408386  0.14450382] ... reward: -0.00 ... done: False\n",
      "\n",
      "step: 27 ... state: [-0.06193202 -0.00044497  0.03370081 -0.19082911] ... action: [-0.55383676  0.905498   -0.10574924  0.69281733] ... reward: 0.03 ... done: False\n",
      "\n",
      "step: 28 ... state: [-0.051424    0.02098587  0.05230323 -0.20379299] ... action: [ 0.39895856 -0.4051261   0.62759566 -0.20698851] ... reward: -0.10 ... done: False\n",
      "\n",
      "step: 29 ... state: [-0.06299262 -0.02316376  0.00516007 -0.23512314] ... action: [0.7622064  0.16254574 0.7634707  0.38506317] ... reward: -0.20 ... done: False\n",
      "\n",
      "step: 30 ... state: [-0.09091111 -0.05587644 -0.00822925 -0.24260347] ... action: [0.45050856 0.00264876 0.91216725 0.2879804 ] ... reward: -0.21 ... done: False\n",
      "\n",
      "step: 31 ... state: [-0.12328134 -0.06480013 -0.00894084 -0.25487295] ... action: [-0.1522899   0.21278642 -0.9616136  -0.39685038] ... reward: -0.08 ... done: False\n",
      "\n",
      "step: 32 ... state: [-0.13359198 -0.02068608  0.02728035 -0.26458939] ... action: [ 0.32034707 -0.41984478  0.23603086 -0.1424626 ] ... reward: -0.14 ... done: False\n",
      "\n",
      "step: 33 ... state: [-0.15555918 -0.04397695  0.00324959 -0.29029831] ... action: [-0.7290519  -0.40343535  0.13992982  0.18174553] ... reward: -0.08 ... done: False\n",
      "\n",
      "step: 34 ... state: [-0.16584955 -0.02060399  0.02321209 -0.29936678] ... action: [ 0.1486505   0.30640164  0.30420655 -0.13716313] ... reward: -0.10 ... done: False\n",
      "\n",
      "step: 35 ... state: [-0.18408139 -0.03649281  0.01837843 -0.30734798] ... action: [ 0.7930932  -0.26487625 -0.12827015  0.78384674] ... reward: 0.01 ... done: False\n",
      "\n",
      "step: 36 ... state: [-0.19805005 -0.03132685  0.164157   -0.11710586] ... action: [ 0.61238796  0.40777716 -0.79954624  0.83896524] ... reward: 0.09 ... done: False\n",
      "\n",
      "step: 37 ... state: [-0.20225367 -0.01000867  0.24649635 -0.03974168] ... action: [ 0.4284826  0.997694  -0.7011034  0.7362521] ... reward: 0.16 ... done: False\n",
      "\n",
      "step: 38 ... state: [-0.1976047   0.00892237  0.29996349 -0.01900196] ... action: [-0.67501414  0.23111913 -0.75236005  0.69601643] ... reward: 0.23 ... done: False\n",
      "\n",
      "step: 39 ... state: [-0.18641326  0.02229541  0.32939836 -0.01390881] ... action: [ 0.6146379   0.13820148 -0.1856334  -0.861666  ] ... reward: 0.18 ... done: False\n",
      "\n",
      "step: 40 ... state: [-0.18453719  0.00367533  0.3062229  -0.04439933] ... action: [ 0.39485756 -0.09291463  0.4441112   0.73276466] ... reward: 0.10 ... done: False\n",
      "\n",
      "step: 41 ... state: [-0.19742368 -0.02579588  0.29754913 -0.04535078] ... action: [ 0.951043    0.7116067  -0.97657186 -0.28004387] ... reward: 0.06 ... done: False\n",
      "\n",
      "step: 42 ... state: [-0.21219555 -0.02962501  0.30212022 -0.05323354] ... action: [ 0.4599811  -0.65674067  0.04207321 -0.89132404] ... reward: 0.03 ... done: False\n",
      "\n",
      "step: 43 ... state: [-0.23616056 -0.04850845  0.28818326 -0.078718  ] ... action: [-0.60000694 -0.9629564   0.5873954  -0.5521506 ] ... reward: 0.00 ... done: False\n",
      "\n",
      "step: 44 ... state: [-0.26090774 -0.04959107  0.27986046 -0.10284402] ... action: [-0.30929664  0.8561626   0.4088288  -0.93632215] ... reward: 0.04 ... done: False\n",
      "\n",
      "step: 45 ... state: [-0.28439698 -0.04774065  0.30843078 -0.0940898 ] ... action: [-0.6706117   0.2429568   0.15445718 -0.5242144 ] ... reward: 0.06 ... done: False\n",
      "\n",
      "step: 46 ... state: [-0.30849427 -0.0482289   0.30696244 -0.11227198] ... action: [0.868428   0.22793192 0.07126561 0.17981996] ... reward: -0.04 ... done: False\n",
      "\n",
      "step: 47 ... state: [-0.3500239  -0.08307266  0.2890943  -0.12031419] ... action: [ 0.46024406 -0.37611002 -0.20355788 -0.5803125 ] ... reward: -0.11 ... done: False\n",
      "\n",
      "step: 48 ... state: [-0.399111   -0.09816025  0.25251168 -0.1515935 ] ... action: [-0.62761396  0.8887448   0.4791016  -0.01908238] ... reward: -0.06 ... done: False\n",
      "\n",
      "step: 49 ... state: [-0.4455983  -0.09374815  0.31029173 -0.04928394] ... action: [-0.5451707  -0.49128702 -0.88394165 -0.13116676] ... reward: 0.08 ... done: False\n",
      "\n",
      "step: 50 ... state: [-0.46710712 -0.04328015  0.34142896 -0.04849005] ... action: [-0.37640825  0.39268696 -0.24449632 -0.64079267] ... reward: 0.13 ... done: False\n",
      "\n",
      "step: 51 ... state: [-0.48298436 -0.03178852  0.36070501 -0.06116512] ... action: [-0.9506425  -0.86550075  0.35878554 -0.09260631] ... reward: 0.14 ... done: False\n",
      "\n",
      "step: 52 ... state: [-0.49191603 -0.01795763  0.34282468 -0.09466083] ... action: [ 0.07315842  0.7933426   0.9806779  -0.56620604] ... reward: 0.05 ... done: False\n",
      "\n",
      "step: 53 ... state: [-0.51890928 -0.05394806  0.34488936 -0.09177715] ... action: [ 0.3261564  -0.47335523 -0.958698    0.5167573 ] ... reward: 0.10 ... done: False\n",
      "\n",
      "step: 54 ... state: [-0.53505522 -0.03229411  0.34191267 -0.1212245 ] ... action: [-0.3599657  -0.2330722   0.17663422  0.6620969 ] ... reward: 0.13 ... done: False\n",
      "\n",
      "step: 55 ... state: [-0.54846114 -0.02681397  0.33551373 -0.14339726] ... action: [ 0.2579637   0.7453013  -0.45291594  0.59609365] ... reward: 0.14 ... done: False\n",
      "\n",
      "step: 56 ... state: [-0.56074768 -0.02435992  0.35837188 -0.15851346] ... action: [-0.6287281   0.9055833   0.37497655 -0.5689846 ] ... reward: 0.02 ... done: False\n",
      "\n",
      "step: 57 ... state: [-0.58809942 -0.05458705  0.31637567 -0.16989294] ... action: [ 0.8947412   0.46171162 -0.49211672 -0.57337606] ... reward: -0.02 ... done: False\n",
      "\n",
      "step: 58 ... state: [-0.62288105 -0.06955498  0.31115524 -0.18012203] ... action: [ 0.03640143 -0.94867456 -0.5850598  -0.15062906] ... reward: 0.02 ... done: False\n",
      "\n",
      "step: 59 ... state: [-0.65057796 -0.05543641  0.287636   -0.20323692] ... action: [-0.25166005 -0.07284915 -0.4447426   0.1735687 ] ... reward: 0.08 ... done: False\n",
      "\n",
      "step: 60 ... state: [-0.67282945 -0.04444705  0.29666224 -0.22489305] ... action: [ 0.7277112  -0.76493627  0.03475821 -0.7358638 ] ... reward: -0.05 ... done: False\n",
      "\n",
      "step: 61 ... state: [-0.71060455 -0.07557114  0.27581852 -0.22766794] ... action: [ 0.43371937 -0.2078806   0.13084263 -0.6334403 ] ... reward: -100.00 ... done: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets play a random episode\n",
    "\n",
    "state = env.reset()\n",
    "done = False\n",
    "step = 0\n",
    "while (not done):\n",
    "    action = env.action_space.sample()\n",
    "    next_state,reward,done,_= env.step(action)\n",
    "    \n",
    "    print (\"step: {} ... state: {} ... action: {} ... reward: {:.2f} ... done: {}\\n\".format(step,state[:4],\n",
    "                                                                                      action,reward,done))  \n",
    "    state = next_state\n",
    "    step+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the Agent with DDPG\n",
    "\n",
    "Run the code cell below to train the agent from scratch.  Alternatively, you can skip to the next code cell to load the pre-trained weights from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parminder0407/anaconda3/envs/cv3/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50 ... Average reward: -41.02 ... Max reward: -27.76\n",
      "Episode 100 ... Average reward: -47.21 ... Max reward: -27.76\n",
      "Episode 150 ... Average reward: -53.23 ... Max reward: -27.76\n",
      "Episode 200 ... Average reward: -74.31 ... Max reward: -20.66\n",
      "Episode 250 ... Average reward: -103.81 ... Max reward: -20.66\n",
      "Episode 300 ... Average reward: -97.27 ... Max reward: -20.66\n",
      "Episode 350 ... Average reward: -76.52 ... Max reward: -20.66\n",
      "Episode 400 ... Average reward: -61.52 ... Max reward: -20.66\n",
      "Episode 450 ... Average reward: -74.29 ... Max reward: -20.66\n",
      "Episode 500 ... Average reward: -77.98 ... Max reward: -20.66\n",
      "Episode 550 ... Average reward: -81.07 ... Max reward: -20.66\n",
      "Episode 600 ... Average reward: -111.62 ... Max reward: -20.66\n",
      "Episode 650 ... Average reward: -118.46 ... Max reward: -20.66\n",
      "Episode 700 ... Average reward: -118.95 ... Max reward: -20.66\n",
      "Episode 750 ... Average reward: -120.90 ... Max reward: -20.66\n",
      "Episode 800 ... Average reward: -118.51 ... Max reward: -20.66\n",
      "Episode 850 ... Average reward: -113.37 ... Max reward: -20.66\n",
      "Episode 900 ... Average reward: -109.75 ... Max reward: -20.66\n",
      "Episode 950 ... Average reward: -92.87 ... Max reward: -20.66\n",
      "Episode 1000 ... Average reward: -95.60 ... Max reward: -20.66\n",
      "Episode 1050 ... Average reward: -115.03 ... Max reward: -20.66\n",
      "Episode 1100 ... Average reward: -113.54 ... Max reward: -20.66\n",
      "Episode 1150 ... Average reward: -111.77 ... Max reward: -20.66\n",
      "Episode 1200 ... Average reward: -111.82 ... Max reward: -20.66\n",
      "Episode 1250 ... Average reward: -117.83 ... Max reward: -20.66\n",
      "Episode 1300 ... Average reward: -118.00 ... Max reward: -20.66\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2060cb14c1bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/learning/rl_bipedal/ddpg_agent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# Learn, if enough samples are available in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mexperiences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGAMMA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/learning/rl_bipedal/ddpg_agent.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mnext_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_state\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mdones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/learning/rl_bipedal/ddpg_agent.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mnext_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_state\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mdones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_episodes=2000\n",
    "max_t=700\n",
    "scores_deque = deque(maxlen=100)\n",
    "scores = []\n",
    "max_score = -np.Inf\n",
    "for i_episode in range(1, n_episodes+1):\n",
    "    state = env.reset()\n",
    "    agent.reset()\n",
    "    score = 0\n",
    "    for t in range(max_t):\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        agent.step(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        score += reward\n",
    "        if done:\n",
    "            break \n",
    "    scores_deque.append(score)\n",
    "    scores.append(score)\n",
    "    if max_score<score:\n",
    "        max_score=score\n",
    "    #print('\\rEpisode {}\\tAverage Score: {:.2f}\\tScore: {:.2f}'.format(i_episode, np.mean(scores_deque), score), end=\"\")\n",
    "    if i_episode % 50 == 0:\n",
    "        torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "        torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "        print('Episode {} ... Average reward: {:.2f} ... Max reward: {:.2f}'.format(i_episode,\n",
    "                                                                                      np.mean(scores_deque),max_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Watch a Smart Agent!\n",
    "\n",
    "In the next code cell, you will load the trained weights from file to watch a smart agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to animate a list of frames\n",
    "def animate_frames(frames):\n",
    "    plt.figure(dpi = 72)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # color option for plotting\n",
    "    # use Greys for greyscale\n",
    "    cmap = None if len(frames[0].shape)==3 else 'Greys'\n",
    "    patch = plt.imshow(frames[0], cmap=cmap)  \n",
    "\n",
    "    fanim = animation.FuncAnimation(plt.gcf(), \\\n",
    "        lambda x: patch.set_data(frames[x]), frames = len(frames), interval=30)\n",
    "    \n",
    "    display(display_animation(fanim, default_mode='once'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.actor_local.load_state_dict(torch.load('checkpoint_actor.pth'))\n",
    "agent.critic_local.load_state_dict(torch.load('checkpoint_critic.pth'))\n",
    "\n",
    "frames = []\n",
    "state = env.reset()\n",
    "agent.reset()\n",
    "for t in range(1000):\n",
    "    action = agent.act(state)\n",
    "    frames.append(env.render(mode='rgb_array')) \n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    state=next_state\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "env.close()\n",
    "animate_frames(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv3",
   "language": "python",
   "name": "cv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
